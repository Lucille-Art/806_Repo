{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as r\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeed scraping \n",
    "- Jobs\n",
    "- Companies\n",
    "- Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Indeed] Page 0 is done.\n",
      "[Indeed] Page 5 is done.\n",
      "[Indeed] Page 10 is done.\n",
      "[Indeed] Page 15 is done.\n",
      "[Indeed] Page 20 is done.\n",
      "[Indeed] Page 25 is done.\n",
      "[Indeed] Page 30 is done.\n",
      "[Indeed] Page 35 is done.\n",
      "[Indeed] Page 40 is done.\n",
      "[Indeed] Page 45 is done.\n",
      "[Indeed] Page 50 is done.\n",
      "[Indeed] Page 55 is done.\n",
      "[Indeed] Page 60 is done.\n",
      "Indeed is done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step=0\n",
    "i=10\n",
    "\n",
    "locations_indeed =[]\n",
    "companies_indeed =[]\n",
    "jobs_indeed =[]\n",
    "dates_indeed =[]\n",
    "rates_indeed=[]\n",
    "rates=[]\n",
    "\n",
    "while i>=0:\n",
    "    url1=f'https://www.indeed.fr/jobs?q=data+analyst&start={i}'\n",
    "    resp_indeed=r.get(url1)\n",
    "    soup_indeed = BeautifulSoup(resp_indeed.content)\n",
    "\n",
    "    if step%5==0:\n",
    "        time.sleep(2.4)\n",
    "        print('[Indeed] Page',step,'is done.')\n",
    "\n",
    "    locations_indeed += [i.text for j in [i.select('.location') for i in soup_indeed.select('div.jobsearch-SerpJobCard')] for i in j]       \n",
    "    companies_indeed += [i.text.strip('\\n').title() for i in soup_indeed.select('span.company')]\n",
    "    jobs_indeed += [i.text.lower().strip('\\n (h/f) h/f').capitalize() for i in soup_indeed.select('h2')]\n",
    "    dates_indeed += [i.text.lower().lstrip('il y a plus de').rstrip('jours ') for i in soup_indeed.select('span.date')]\n",
    "    for j in [i.select('.ratingsContent') for i in soup_indeed.select('div.jobsearch-SerpJobCard')]:\n",
    "        if j==[]:\n",
    "            rates.append('Not specified')\n",
    "        else:\n",
    "            rates.append([k.text.strip('\\n') for k in j])\n",
    "\n",
    "    step+=1\n",
    "    i+=10\n",
    "\n",
    "    if i>=660:\n",
    "        print('Indeed is done.\\n')\n",
    "\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "dict_indeed = {'Job': jobs_indeed,\n",
    "    'Company': companies_indeed,\n",
    "    'Location': locations_indeed,\n",
    "    'Publication Date': dates_indeed,\n",
    "    'Company\\'s rate':rates}\n",
    "\n",
    "\n",
    "df1=pd.DataFrame(dict_indeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pôle Emploi] Page 0 is done.\n",
      "[Pôle Emploi] Page 5 is done.\n",
      "[Pôle Emploi] Page 10 is done.\n",
      "[Pôle Emploi] Page 15 is done.\n",
      "Pôle Emploi is done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step=0\n",
    "i=0\n",
    "\n",
    "locations_pe =[]\n",
    "jobs_pe =[]\n",
    "dates_pe = []\n",
    "\n",
    "while i>=0:\n",
    "    url2=f'https://candidat.pole-emploi.fr/offres/recherche.rechercheoffre:afficherplusderesultats/{i}-{i+9}?motsCles=data+analyst&offresPartenaires=true&range={i-10}-{i-1}&rayon=10&tri=0'\n",
    "    resp_pe=r.get(url2)\n",
    "    soup_pe = BeautifulSoup(resp_pe.content)\n",
    "\n",
    "    if step%5==0:\n",
    "        time.sleep(2.4)\n",
    "        print('[Pôle Emploi] Page',step,'is done.')\n",
    "\n",
    "    locations_pe += [i.text.strip('\\n').title() for i in soup_pe.select('p.subtext')]\n",
    "    jobs_pe += [i.text.lower().strip('\\n (h/f) h/f').capitalize() for i in soup_pe.select('h2.t4')]\n",
    "    dates_pe += [i.text.lower().strip('\\n publié il y a jours de') for i in soup_pe.select('p.date')]\n",
    "\n",
    "    step +=1\n",
    "    i+=10\n",
    "\n",
    "    if i>=185:\n",
    "        print('Pôle Emploi is done.')\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "dict_pe = {'Job': jobs_pe,\n",
    "         'Location': locations_pe,\n",
    "          'Publication date':dates_pe}\n",
    "\n",
    "df2=pd.DataFrame(dict_pe)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Company's rate</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data analyst / data manager (h/f) (siège du gr...</td>\n",
       "      <td>Hess Automobile</td>\n",
       "      <td>Bischheim (67)</td>\n",
       "      <td>7</td>\n",
       "      <td>[3,0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data quality analyst</td>\n",
       "      <td>Auchan Retail France</td>\n",
       "      <td>Villeneuve-d'Ascq (59)</td>\n",
       "      <td>jourd'hui</td>\n",
       "      <td>[3,7]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analyst</td>\n",
       "      <td>Maif</td>\n",
       "      <td>Niort (79)</td>\n",
       "      <td>2</td>\n",
       "      <td>[3,5]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyst - data migration - workday</td>\n",
       "      <td>Everbe</td>\n",
       "      <td>Bordeaux (33)</td>\n",
       "      <td>30</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/web analyst (h/f) - stage/alternance</td>\n",
       "      <td>Maisons Du Monde</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>4</td>\n",
       "      <td>[3,3]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Advanced data engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ainabl Technologies France\\n - 75 - Paris 01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Consultant data senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Synergy France\\n - 59 - Lezennes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30 jours\\n\\noffre avec peu de candidat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Data analyste/spécialiste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92 - Neuilly Sur Seine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Analyste décisionnel - business intelligence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fed It\\n - 69 - Bron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Études et prospectives socio-économiques</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92 - Meudon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Job               Company  \\\n",
       "0    Data analyst / data manager (h/f) (siège du gr...       Hess Automobile   \n",
       "1                                 Data quality analyst  Auchan Retail France   \n",
       "2                                         Data analyst                  Maif   \n",
       "3                   Analyst - data migration - workday                Everbe   \n",
       "4            Data/web analyst (h/f) - stage/alternance      Maisons Du Monde   \n",
       "..                                                 ...                   ...   \n",
       "175                             Advanced data engineer                   NaN   \n",
       "176                             Consultant data senior                   NaN   \n",
       "177                          Data analyste/spécialiste                   NaN   \n",
       "178       Analyste décisionnel - business intelligence                   NaN   \n",
       "179           Études et prospectives socio-économiques                   NaN   \n",
       "\n",
       "                                         Location Publication Date  \\\n",
       "0                                  Bischheim (67)                7   \n",
       "1                          Villeneuve-d'Ascq (59)        jourd'hui   \n",
       "2                                      Niort (79)                2   \n",
       "3                                   Bordeaux (33)              30    \n",
       "4                                      Paris (75)                4   \n",
       "..                                            ...              ...   \n",
       "175  Ainabl Technologies France\\n - 75 - Paris 01              NaN   \n",
       "176              Synergy France\\n - 59 - Lezennes              NaN   \n",
       "177                        92 - Neuilly Sur Seine              NaN   \n",
       "178                          Fed It\\n - 69 - Bron              NaN   \n",
       "179                                   92 - Meudon              NaN   \n",
       "\n",
       "    Company's rate                        Publication date  \n",
       "0            [3,0]                                     NaN  \n",
       "1            [3,7]                                     NaN  \n",
       "2            [3,5]                                     NaN  \n",
       "3    Not specified                                     NaN  \n",
       "4            [3,3]                                     NaN  \n",
       "..             ...                                     ...  \n",
       "175            NaN                                      30  \n",
       "176            NaN  30 jours\\n\\noffre avec peu de candidat  \n",
       "177            NaN                                      30  \n",
       "178            NaN                                      'h  \n",
       "179            NaN                                       9  \n",
       "\n",
       "[1285 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([df1,df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Company'] = df['Company'].fillna('Not specified')\n",
    "df['Company\\'s rate'] = df['Company\\'s rate'].fillna('Not specified')\n",
    "df['Publication date'] = df['Publication date'].fillna(100)\n",
    "df.loc[df['Publication date']=='d\\'h', 'Publication date']=1\n",
    "df.loc[df['Publication date']=='jourd\\'hui', 'Publication date']=0\n",
    "df.loc[df['Publication date']=='bliée à l\\'instant', 'Publication date']=0\n",
    "df.loc[df['Publication date']=='Not specified', 'Publication date']=100\n",
    "df.loc[df['Publication date']=='h', 'Publication date']=1\n",
    "df.loc[df['Publication date']=='\\'h', 'Publication date']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', \"jourd'hui\", '2', '30\\xa0', '4', '23', '15', '1', '6', '26',\n",
       "       \"bliée à l'instant\", '19', '13', '16', '14', '9', '12', '22', '8',\n",
       "       '5', '11', '21', '27', '20', '28', '3', '29', '18', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Publication Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_indeed =[i.select('.ratingsContent') for i in soup_indeed.select('div.jobsearch-SerpJobCard')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates=[]\n",
    "for j in [i.select('.ratingsContent') for i in soup_indeed.select('div.jobsearch-SerpJobCard')]:\n",
    "    if j==[]:\n",
    "        rates.append('unknown')\n",
    "    else:\n",
    "        rates.append([k.text.strip('\\n') for k in j])\n",
    "        \n",
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_indeed = soup_indeed.select('span.location, div.location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_indeed = [i.text.lower().lstrip('il y a plus de').rstrip('jours ') for i in soup_indeed.select('span.date')]\n",
    "len(dates_indeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indeed = {'Job': jobs_indeed,\n",
    "        'Company': companies_indeed,\n",
    "        'Location': locations_indeed,\n",
    "              'Date':dates_indeed,\n",
    "              'Rates':rates}\n",
    "\n",
    "df_indeed = pd.DataFrame(dict_indeed)\n",
    "df_indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=0\n",
    "i=20\n",
    "\n",
    "while i>=0:\n",
    "    url_indeed=f'https://www.indeed.fr/jobs?q=data+analyst&start={i-10}'\n",
    "    resp_indeed=r.get(url_indeed)\n",
    "    \n",
    "    if step%5==0:\n",
    "        print('Page',step,'is done.')\n",
    "    \n",
    "    locations_indeed += [i.text for j in [i.select('.location') for i in soup_indeed.select('div.jobsearch-SerpJobCard')] for i in j]\n",
    "    companies_indeed += [i.text.strip('\\n').title() for i in soup_indeed.select('span.company')]\n",
    "    jobs_indeed += [i.text.strip('\\n').capitalize() for i in soup_indeed.select('h2')]\n",
    "    dates_indeed += [i.text.lower().lstrip('il y a plus de').rstrip('jours ') for i in soup_indeed.select('span.date')]\n",
    "    rates_indeed +=[i.select('span.ratingsContent') for i in soup_indeed.select('div.jobsearch-SerpJobCard')]\n",
    "\n",
    "\n",
    "    step +=1\n",
    "    i+=10\n",
    "    \n",
    "    if i>=40:\n",
    "        print(len(locations_indeed),len(jobs_indeed),len(rates_indeed))\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pole Emploi scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pe = 'https://candidat.pole-emploi.fr/offres/recherche.rechercheoffre:afficherplusderesultats/10-19?motsCles=data+analyst&offresPartenaires=true&rayon=10&tri=0'\n",
    "resp_pe = r.get(url_pe)\n",
    "soup_pe = BeautifulSoup(resp_pe.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_pe = [i.text.strip('\\n').capitalize() for i in soup_pe.select('h2.t4')]\n",
    "jobs_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_pe = [i.text.strip('\\n').title() for i in soup_pe.select('p.subtext')]\n",
    "dates_pe = [i.text.lower().strip('\\n publié il y a jours') for i in soup_pe.select('p.date')]\n",
    "dates_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=0\n",
    "i=0\n",
    "\n",
    "while i>=0:\n",
    "    url_pe=f'https://candidat.pole-emploi.fr/offres/recherche.rechercheoffre:afficherplusderesultats/{i}-{i+9}?motsCles=data+analyst&offresPartenaires=true&range={i-10}-{i-1}&rayon=10&tri=0'\n",
    "    resp_pe=r.get(url_pe)\n",
    "    \n",
    "    if step%5==0:\n",
    "        time.sleep(2.4)\n",
    "        print('Page',step,'is done.')\n",
    "    \n",
    "    locations_pe += [i.text.strip('\\n').title() for i in soup_pe.select('p.subtext')]\n",
    "    jobs_pe += [i.text.strip('\\n').capitalize() for i in soup_pe.select('h2.t4')]\n",
    "\n",
    "\n",
    "\n",
    "    step +=1\n",
    "    i+=10\n",
    "    \n",
    "    if i>=185:\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "\n",
    "dict_pe = {'Job': jobs_pe,\n",
    "               'Location': locations_pe}\n",
    "\n",
    "df_pe = pd.DataFrame(dict_pe)\n",
    "df_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
